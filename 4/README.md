제4장: 레이트 리미터 설계

레이트 리미터(Rate Limiter)란?

레이트 리미터는 클라이언트나 서비스가 보내는 트래픽의 속도를 제한하는 기법

특히 HTTP API에서 레이트 리미터는 일정 기간 동안 클라이언트가 보낼 수 있는 요청 수를 제한

요청 횟수가 미리 설정된 임계값을 초과하면 초과 요청이 차단

레이트 리미터 적용 예시:

사용자는 1초에 2개 이상의 게시글을 작성할 수 없다.

동일한 IP 주소에서 하루 최대 10개의 계정을 생성할 수 있다.

동일한 디바이스에서 일주일에 최대 5번만 보상을 받을 수 있다.

레이트 리미터가 필요한 이유?

리소스 보호 (DoS 공격 방지)

의도적이든 비의도적이든 과도한 요청을 차단하여 서버 다운을 방지

예시:

트위터(Twitter) → 3시간에 300개 트윗 제한

구글 문서 API(Google Docs API) → 60초당 300개 읽기 요청 제한

비용 절감
과도한 API 호출을 제한하면 서버 비용 절감
특히 유료 API(예: 신용 조회, 결제 처리, 건강 기록 조회 등)의 경우 호출 횟수를 제한해야 비용 절감이 가능

서버 과부하 방지
봇이나 잘못된 사용자 행동으로 인한 과도한 트래픽을 필터링

중요한 API가 정상적으로 작동하도록 보호


레이트 리미팅 알고리즘 (예: 토큰 버킷, 슬라이딩 윈도우, 고정 윈도우 등)

어디에 레이트 리미터를 적용할 것인가? (클라이언트, API 게이트웨이, 서버 등)

분산 시스템에서 레이트 리미팅을 어떻게 처리할 것인가?

![image](https://github.com/user-attachments/assets/db407866-2f05-4bbb-8d88-1c9ca48189e7)

레이트 리미터 배치 방식 (추가 옵션: 미들웨어 방식)
바로 API 서버에 직접 배치하는 대신, 요청을 제어하는 미들웨어 (Middleware) 방식

📍 미들웨어 방식이란?
✅ API 서버 앞에 별도의 미들웨어를 두어 요청을 제한하는 방식
✅ API 요청이 서버에 도달하기 전에 미들웨어가 먼저 검증 후 차단

📌 레이트 리미터 배치 비교
배치 방식	장점	단점
클라이언트 측	- 서버 부담 감소
- 빠른 차단 가능	- 신뢰할 수 없는 환경 (우회 가능)
- 클라이언트마다 적용 필요
서버 측	- 강력한 제한 가능
- 신뢰할 수 있는 환경	- 서버 부하 증가
미들웨어 방식	- API 서버 부담 감소
- 중앙 집중식 제어 가능	- 미들웨어 장애 시 전체 API 영향 가능
💡 → 최적의 선택: 미들웨어 방식은 서버 부담을 줄이면서도 중앙에서 제어할 수 있기 때문에 확장성이 높은 대규모 시스템에서 유용하게 쓰일 수 있음.

![image](https://github.com/user-attachments/assets/dfbf7996-8fe0-4195-91c0-15a6cf9248db)

레이트 리미터 작동 예시 (그림 4-3)
🛠 시나리오:
시스템에서 1초에 최대 2개의 요청만 허용한다고 가정.

클라이언트가 1초 안에 3개의 요청을 보냄.

📍 요청 처리 흐름
1️⃣ 첫 번째 요청 → 정상 처리 (API 서버로 전달)
2️⃣ 두 번째 요청 → 정상 처리 (API 서버로 전달)
3️⃣ 세 번째 요청 → 🚫 차단 (HTTP 429 Too Many Requests 응답 반환)

📌 HTTP 429 응답 코드란?
🔹 HTTP 429 Too Many Requests

클라이언트가 너무 많은 요청을 보낼 경우 반환되는 표준 HTTP 응답 코드.

보통 Retry-After 헤더를 포함하여 얼마 후 다시 시도할 수 있는지 안내함.

![image](https://github.com/user-attachments/assets/f23eb871-2c2d-40ee-a85b-2bd57454833a)

토큰 버킷 (Token Bucket) 알고리즘
🔹 레이트 리미팅을 위한 가장 널리 사용되는 알고리즘 중 하나
🔹 Amazon, Stripe 등 많은 기업이 API 요청 제어에 사용
🔹 간단하고 이해하기 쉬우며, 네트워크 트래픽 제어에 적합

📍 토큰 버킷 작동 방식
✅ 1. 토큰 버킷(컨테이너)은 사전 정의된 최대 용량을 가짐.
✅ 2. 일정한 속도로 토큰이 버킷에 추가됨.
✅ 3. 요청을 처리하려면 버킷에서 토큰을 꺼내야 함.
✅ 4. 버킷이 비어 있으면 새로운 요청은 거부됨.
✅ 5. 버킷이 가득 차면 초과 토큰은 버려짐.

📍 장점 & 단점
✔ 장점:

요청을 부드럽게 분배할 수 있음 (Burst 트래픽 허용 가능)

구현이 간단하고 확장성이 좋음

실시간 처리 시스템에 적합

✖ 단점:

특정 시점에 과도한 요청(Burst)이 발생할 가능성이 있음

일정한 속도로 토큰이 채워지므로, 일부 시나리오에서는 정밀한 제어가 어려울 수 있음

![image](https://github.com/user-attachments/assets/932d2d78-f1ae-40ec-be32-dfee0b1cca31)

![image](https://github.com/user-attachments/assets/57cea92c-3464-4374-b13d-249e803c12cf)

🔹 버킷 크기: 4 (최대 4개의 요청 처리 가능)
🔹 토큰 리필 속도: 1분에 4개씩 추가됨
🔹 요청이 올 때마다 1개의 토큰을 소모함

![image](https://github.com/user-attachments/assets/1aec62f0-40fa-4c59-94dc-54abe1316d9e)

📌 Leaking Bucket (누수 버킷) 알고리즘 개요
🔹 기본 개념:

버킷을 FIFO(First-In-First-Out) 큐로 활용하여 요청을 저장

고정된 속도로 요청을 처리하여 네트워크나 서버가 과부하되지 않도록 제어

버킷이 가득 차면 초과 요청은 버려짐 (429 응답 반환)

📍 Leaking Bucket 알고리즘 동작 방식
1️⃣ 요청이 들어오면 큐에 추가
2️⃣ 큐가 가득 차면 새로운 요청을 거부 (429 Too Many Requests 응답)
3️⃣ 고정된 속도로 요청을 하나씩 처리 (균일한 부하 유지)
4️⃣ 서버 과부하를 방지하면서 일정한 속도로 요청을 처리

📍 예제 시뮬레이션
🔹 버킷 크기: 5 (최대 5개 요청 저장 가능)
🔹 처리 속도: 초당 1개 요청 처리
🔹 요청 시나리오:

시간(초)	큐 상태	요청 수	처리 여부
0초	🪣 [0]	요청 3개	✅ 3개 큐에 추가
1초	🪣 [2]	요청 2개	✅ 2개 큐에 추가, 1개 처리 (큐 → 3)
2초	🪣 [3]	요청 4개	✅ 2개 추가 (큐 → 5), ❌ 2개 거부 (429)
3초	🪣 [5]	요청 없음	✅ 1개 처리 (큐 → 4)
4초	🪣 [4]	요청 2개	✅ 1개 추가 (큐 → 5), ❌ 1개 거부 (429)
📍 Leaking Bucket vs. Token Bucket
특징	Token Bucket	Leaking Bucket
요청 처리 속도	가변적 (버스트 허용)	고정된 속도
과부하 대응	순간적인 요청 몰림 허용	일정한 속도로 처리하여 부하 분산
큐 사용 여부	❌ 사용 안 함	✅ FIFO 큐 사용
초과 요청 처리	버킷이 비어 있을 경우 요청 대기	큐가 차면 즉시 요청 거부 (429)
사용 사례	API 속도 제한, 과부하 방지	스트리밍, 트래픽 조절
📍 장점과 단점
✔ 장점:

네트워크 트래픽이 일정하게 유지되어 서버 부하가 안정적

순간적인 트래픽 폭주 방지 (DDoS 완화 효과)

FIFO 방식으로 요청 순서 보장

✖ 단점:

버스트 트래픽을 허용하지 않음 → 갑작스러운 요청 몰림 시 거부 발생

큐 크기 제한이 필요 → 너무 크면 메모리 낭비, 작으면 요청이 많이 차단됨

✅ 💡 결론:
Leaking Bucket 알고리즘은 일정한 속도로 트래픽을 처리하여 서버 부하를 제어하는 데 효과적이다.
그러나, 버스트 트래픽이 필요한 경우에는 Token Bucket 알고리즘이 더 적합할 수 있다. 🚀

![image](https://github.com/user-attachments/assets/3693169e-87b7-4f3f-9bcc-de942b468bd8)

:
📌 Fixed Window Counter (고정 윈도우 카운터) 알고리즘 개요
🔹 기본 개념:

시간을 고정된 크기의 윈도우(예: 1초, 1분, 1시간)로 나눔

각 윈도우마다 요청 수를 카운트하여 초과하면 차단

윈도우가 새로 시작되면 카운트 초기화

📍 Fixed Window Counter 알고리즘 동작 방식
1️⃣ 요청이 들어오면 현재 시간 윈도우의 카운터를 증가
2️⃣ 카운트가 임계값(Threshold)에 도달하면 추가 요청 차단 (429 응답 반환)
3️⃣ 새로운 시간 윈도우가 시작되면 카운트가 리셋되고 다시 요청 가능

📍 예제 시뮬레이션
🔹 윈도우 크기: 1초
🔹 최대 요청 수: 3개
🔹 요청 시나리오:

시간(초)	요청 수	카운터 상태	요청 처리 여부
0-1초	요청 2개	✅ 2/3	허용
1-2초	요청 4개	❌ 3/3 (1개 허용, 3개 차단)	1개 허용, 3개 429
2-3초	요청 1개	✅ 1/3	허용
3-4초	요청 3개	✅ 3/3	허용
4-5초	요청 2개	✅ 2/3	허용
📍 Fixed Window Counter vs. 다른 알고리즘 비교
특징	Fixed Window Counter	Token Bucket	Leaking Bucket
요청 처리 방식	고정된 시간 단위로 제한	토큰이 있으면 요청 허용	일정한 속도로 요청 처리
순간 트래픽 (Burst) 허용 여부	❌ (초과 시 차단)	✅ (버스트 허용)	❌ (FIFO 큐가 차면 차단)
트래픽 분포	일정하지만, 경계에서 과부하 발생 가능	자연스럽게 부하 분산	부하가 균등 분산됨
적합한 사례	API 요청 제한	일정량의 요청을 처리하는 서비스	지속적으로 일정한 트래픽이 필요한 경우
📍 장점과 단점
✔ 장점:

간단한 구현 (시간별 카운터만 관리)

메모리 사용량이 적음 (윈도우당 카운터만 저장하면 됨)

일정한 요청 패턴에 적합 (예: "1초당 1000개 요청 가능")

✖ 단점:

윈도우 경계 문제 → 예를 들어, 0.9초에 3개, 1.1초에 3개 요청하면 총 6개 허용

버스트 트래픽 차단 어려움 → 짧은 시간에 많은 요청이 들어오면 초과 요청 차단

✅ 💡 결론:
Fixed Window Counter 알고리즘은 간단하고 메모리 효율적이지만, 윈도우 경계에서 과부하가 발생할 수 있다.
이를 해결하려면 Sliding Window Counter 또는 Token Bucket 같은 방법이 더 적합할 수

![image](https://github.com/user-attachments/assets/13fbcb53-3cda-4248-8de1-b063ac33939a)

 Sliding Window Log (슬라이딩 윈도우 로그) 알고리즘 개요
🔹 기본 개념:

고정 윈도우 카운터(Fixed Window Counter)의 문제점인 경계 문제 해결

요청 시간을 개별적으로 저장하여 더 정밀하게 요청을 제한

이전 요청들을 정렬된 로그로 관리하면서 최신 윈도우 내 요청 개수 확인

📍 Sliding Window Log 알고리즘 동작 방식
1️⃣ 각 요청의 타임스탬프를 저장 (예: Redis Sorted Set 사용)
2️⃣ 새로운 요청이 들어오면, 오래된 타임스탬프 제거
3️⃣ 현재 윈도우 내 타임스탬프 개수를 확인하여 임계값(Threshold) 초과 여부 판단
4️⃣ 초과하지 않으면 요청 허용, 초과하면 429 에러 반환

📍 예제 시뮬레이션 (최대 5회/분 허용)
시간	요청 발생	저장된 타임스탬프	요청 처리 여부
2:00:00	요청 1개	[2:00:00]	✅ 허용
2:00:15	요청 1개	[2:00:00, 2:00:15]	✅ 허용
2:00:30	요청 2개	[2:00:00, 2:00:15, 2:00:30, 2:00:30]	✅ 허용
2:00:45	요청 1개	[2:00:00, 2:00:15, 2:00:30, 2:00:30, 2:00:45]	✅ 허용 (5/5)
2:00:50	요청 1개	[2:00:15, 2:00:30, 2:00:30, 2:00:45, 2:00:50]	✅ 허용 (2:00:00 제거됨)
🔹 핵심 포인트:

윈도우가 고정된 시간이 아니라 요청의 타임스탬프에 따라 유동적으로 움직임

기존 요청이 오래되면 자동으로 제거 → "경계 문제" 해결

📍 Sliding Window Log vs. Fixed Window Counter 비교
특징	Fixed Window Counter	Sliding Window Log
요청 처리 방식	고정된 시간 단위로 카운트	개별 요청의 타임스탬프 기반 카운트
트래픽 폭증 (Burst) 허용 여부	❌ 경계에서 과부하 발생 가능	✅ 요청이 균등하게 분산됨
메모리 사용량	⬇ 적음 (윈도우당 카운터만 저장)	⬆ 많음 (모든 요청의 타임스탬프 저장)
요청 분포	일정하지만, 경계에서 허용량 초과 가능	자연스럽게 분산됨
적합한 사례	간단한 API 제한	보다 정밀한 제한이 필요한 경우
📍 장점과 단점
✔ 장점:

경계 문제 해결 → 요청이 일정하게 분배됨

보다 정밀한 요청 제한 가능

Token Bucket과 유사한 효과 제공 (단기적인 버스트 요청 허용)

✖ 단점:

메모리 사용량 증가 (모든 요청의 타임스탬프 저장 필요)

처리 속도가 느릴 수 있음 (타임스탬프 정렬, 삭제 연산 필요)

✅ 💡 결론:
Sliding Window Log 알고리즘은 보다 정밀한 요청 제한이 필요할 때 적합하지만, 메모리 사용량이 증가할 수 있다.
이를 개선한 방식으로 Sliding Window Counter 알고리즘이 존재하며, 성능과 정확성을 모두 고려할 수 있다. 🚀

![image](https://github.com/user-attachments/assets/83c9ae0f-b9f4-4ec5-bbf4-bd17645dfb14)

🔹 Sliding Window Counter 알고리즘 개요
📌 개념:

고정 윈도우 카운터(Fixed Window Counter)와 슬라이딩 윈도우 로그(Sliding Window Log)의 장점을 조합

메모리 효율성과 정확성을 모두 고려한 하이브리드 방식

📍 Sliding Window Counter 알고리즘 동작 방식
1️⃣ 요청이 들어오면 현재 시간의 윈도우(예: 1분)와 직전 윈도우의 요청 개수를 조회
2️⃣ 현재 윈도우의 요청 개수는 그대로 사용, 직전 윈도우의 요청 개수는 가중치(weight)를 적용하여 반영
3️⃣ 최종적으로 허용된 요청 개수를 계산 후, 제한 초과 여부 판단
4️⃣ 제한을 초과하면 요청을 거부, 그렇지 않으면 요청 허용

📍 Sliding Window Counter 예제 시뮬레이션 (최대 10회/분 허용)
시간	현재 윈도우 (2:00~2:01)	직전 윈도우 (1:59~2:00)	가중치 적용 후 최종 요청 수	요청 처리 여부
2:00:10	3	5	3 + (5 * 0.5) = 5.5	✅ 허용
2:00:30	5	5	5 + (5 * 0.5) = 7.5	✅ 허용
2:00:50	8	5	8 + (5 * 0.5) = 10.5	❌ 거부 (초과)
2:01:10	2	8	2 + (8 * 0.5) = 6	✅ 허용
🔹 핵심 포인트:

현재 윈도우의 요청 개수와 직전 윈도우의 요청 개수를 활용하여 연속적인 요청 제한

고정된 시간 간격이 아니라 이전 윈도우의 데이터를 일부 반영하여 부드러운 제한 효과

📍 Sliding Window Counter vs. 다른 알고리즘 비교
특징	Fixed Window Counter	Sliding Window Log	Sliding Window Counter
요청 처리 방식	고정된 시간 블록	모든 요청 타임스탬프 저장	최근 요청 개수 기반 카운트
트래픽 폭증 (Burst) 허용 여부	❌ 경계에서 과부하 발생 가능	✅ 요청이 균등하게 분산됨	✅ 부드러운 제한
메모리 사용량	⬇ 적음	⬆ 많음	⬇ 적음 (타임스탬프 저장X)
요청 분포	특정 시점에 집중 가능	자연스럽게 분산됨	자연스럽게 분산됨
적합한 사례	간단한 API 제한	정밀한 요청 제한	성능과 정확성을 동시에 고려
📍 장점과 단점
✔ 장점:

고정 윈도우의 성능 + 슬라이딩 윈도우의 정확성 결합

메모리 사용량이 적음 (모든 타임스탬프 저장 불필요)

경계 문제 해결 → 요청이 자연스럽게 분산됨

✖ 단점:

이전 윈도우의 데이터를 얼마나 반영할지(가중치 설정)가 중요

구현이 비교적 복잡

✅ 💡 결론:
Sliding Window Counter는 성능과 정확성을 모두 고려한 최적의 알고리즘으로, 실무에서 가장 많이 사용되는 방식 중 하나다! 🚀

![image](https://github.com/user-attachments/assets/c63c6098-d2cb-4451-adf1-9952e46c2ee2)

고수준 Rate Limiting 아키텍처
📌 핵심 개념:

요청을 추적하는 카운터(counter)를 유지하여 일정 임계치를 초과하면 차단

저장 위치: 빠른 접근을 위해 데이터베이스 대신 인메모리 캐시 사용

Redis를 활용한 구현이 일반적

📍 Rate Limiting을 위한 Redis 활용 방법
1️⃣ INCR (Increment Counter)

특정 키에 대한 요청 횟수를 증가시킴

예: INCR user:123:requests

2️⃣ EXPIRE (Set Expiration)

카운터의 만료 시간 설정 (자동 리셋)

예: EXPIRE user:123:requests 60 → 60초 후 카운터 자동 삭제

📍 High-Level Architecture (고수준 설계)
1️⃣ 클라이언트 요청 → API Gateway (또는 Load Balancer) → Rate Limiter
2️⃣ Rate Limiter는 Redis에서 현재 요청 수를 조회
3️⃣ 요청이 허용된 한도를 초과하면 HTTP 429 (Too Many Requests) 반환
4️⃣ 초과하지 않으면 INCR 실행 후 API 요청 전달

![image](https://github.com/user-attachments/assets/861f007d-3415-4ea7-8ae5-3e52a4cf3bce)

🔹 Redis 기반 Rate Limiting 요청 처리 흐름
📍 요청 처리 단계 (Flow)
1️⃣ 클라이언트가 API 요청을 보냄

요청은 Rate Limiting 미들웨어를 먼저 거침

2️⃣ Rate Limiting 미들웨어에서 Redis에 저장된 카운터 조회

요청한 사용자의 버킷(bucket) 을 확인 (예: rate_limit:user_123)

현재까지의 요청 횟수를 가져옴

3️⃣ 요청 허용 여부 확인

제한 초과: HTTP 429 (Too Many Requests) 반환

허용 가능: API 서버로 요청 전달

4️⃣ 허용된 요청은 카운터 증가 & Redis에 저장

INCR 실행 (요청 횟수 증가)

EXPIRE 설정 (시간 기반 만료 적용)


✔ 속도 제한 규칙은 YAML 파일 또는 DB에서 관리됨
✔ Redis를 사용하여 속도 제한 적용 (INCR, EXPIRE 활용)
✔ API Gateway 또는 미들웨어에서 제한 로직 처리
✔ 429 Too Many Requests 응답과 함께 X-Ratelimit- 헤더 반환*
✔ 성능 최적화를 위해 Redis Cluster 및 Lua 스크립트 활용
✔ 실시간 모니터링 및 로그 분석을 위한 Grafana + ELK Stack 적용

![image](https://github.com/user-attachments/assets/b733d68a-444d-4dcd-9b44-267a7cc85fef)

속도 제한 시스템 아키텍처 (Architecture)
✅ 디스크에 저장된 속도 제한 규칙을 캐시로 불러오기

워커(Worker)가 주기적으로 디스크에서 규칙을 읽어와 캐시에 저장

속도 제한 미들웨어(Rate Limiter Middleware)는 요청이 올 때 캐시에서 규칙을 불러옴

✅ 속도 제한 요청 처리 흐름

클라이언트가 요청을 보냄

요청은 Rate Limiter Middleware 를 먼저 거침

미들웨어가 캐시에서 규칙을 불러와 확인

Redis에서 카운터 및 마지막 요청 시간(timestamp) 조회

결과에 따라 두 가지 처리 가능:

요청이 허용되면 API 서버로 전달

요청이 제한되면 429 응답을 반환하거나 큐(Queue)에 저장

문제 1: 레이스 컨디션 (Race Condition)
⚠️ 문제 발생 예시

Redis에서 현재 카운터 값(예: 3)을 읽음

동시에 두 개의 요청이 도착하여 각각 +1을 수행

두 요청 모두 4를 기록 → 실제로는 5가 되어야 하지만 잘못된 값 저장

![image](https://github.com/user-attachments/assets/b1daa833-da34-4c6b-9af3-efea400fc006)

문제 2: 동기화 이슈 (Synchronization Issue)
✅ 멀티 서버 환경에서 속도 제한 동기화 문제

클라이언트가 Rate Limiter 1 또는 Rate Limiter 2 중 하나에 랜덤하게 연결됨

두 개의 레이트 리미터가 각각 따로 데이터를 저장하면 정확한 제한이 불가능
![image](https://github.com/user-attachments/assets/2c320afd-0077-4a69-ae20-4b33f71b51e0)

✅ 해결책: Redis를 중앙 집중식 저장소로 활용

모든 속도 제한 요청을 단일 Redis 클러스터 로 관리

![image](https://github.com/user-attachments/assets/55168925-afce-4f37-a8d0-3a47780f5bd6)

성능 최적화 (Performance Optimization)
✅ 멀티 데이터 센터 (Multi Data Center) 아키텍처

지리적으로 분산된 엣지 서버(edge servers) 활용

사용자의 가까운 데이터 센터에서 요청을 처리하여 지연 시간(Latency) 최소화

예: Cloudflare는 전 세계 194개 엣지 서버 운영 (2020년 기준)

✅ 최종적 일관성(Eventual Consistency) 모델 사용

즉각적인 동기화보다 일관성 모델을 완화하여 성능 향상

속도 제한 데이터가 즉시 동기화되지 않아도 시스템이 일정 시간이 지나면 정확한 값을 유지

✅ Token Bucket 알고리즘으로 버스트 트래픽 지원

짧은 시간 동안 폭발적으로 증가하는 트래픽 (Burst Traffic) 을 처리하기 위해

일정량의 요청을 미리 허용하고, 점진적으로 리필 (Refill)

![image](https://github.com/user-attachments/assets/2c5c521e-e6d1-48a0-bd17-1e5fa759f239)

모니터링 (Monitoring)
✅ 속도 제한 효과 분석 (Effectiveness Analysis)

속도 제한 규칙이 적절한가?

너무 엄격하면 정상적인 요청이 차단됨

너무 느슨하면 트래픽 과부하 발생

트래픽 급증 대응 (Flash Sales, DDOS 공격 감지)

예: 대규모 할인 행사 시 알고리즘 변경 (Token Bucket 사용)

